import streamlit as st
from openai import OpenAI, APIConnectionError, RateLimitError, OpenAIError
from ui import render_header
# from chroma2 import Chroma2
# import time


# langchain ì¶”ê°€
# langchain = Chroma2.create_langchain("./docs")


def show_tab1():
    render_header()
    st.divider()

    # GPT ê¸°ë³¸ ì„¤ì •
    openai_api_key = st.secrets["OPENAI_API_KEY"]
    client = OpenAI(api_key=openai_api_key)
    gpt_model = "gpt-4o"
    gpt_content = (
        "ë‹¹ì‹ ì€ ì‹ í•œê¸ˆìœµê·¸ë£¹ì˜ ICT ì‚¬ì—…ì •ë³´ë¥¼ ë¶„ì„í•´ì£¼ëŠ” ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê³µì‹œìë£Œ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì‹¤ì— ê·¼ê±°í•œ ì •ë³´ë¥¼ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì œê³µí•©ë‹ˆë‹¤."
    )

    # ì˜ˆì‹œ ë²„íŠ¼
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ì‹ í•œì€í–‰ì˜ ìµœê·¼ ì‹ ì‚¬ì—…ì€?"):
            st.session_state.pending_user_input = "ì‹ í•œì€í–‰ì˜ ìµœê·¼ ì‹ ì‚¬ì—…ì€?"
    with col2:
        if st.button("2025ë…„ AI ê´€ë ¨ ê³µì‹œê°€ ìˆì—ˆì–´?"):
            st.session_state.pending_user_input = "2025ë…„ AI ê´€ë ¨ ê³µì‹œê°€ ìˆì—ˆì–´?"
    with col3:
        if st.button("ì´ë²ˆ ë‹¬ ICT ì…ì°° ê³µê³  ì•Œë ¤ì¤˜"):
            st.session_state.pending_user_input = "ì´ë²ˆ ë‹¬ ICT ì…ì°° ê³µê³  ì•Œë ¤ì¤˜"

    # ë©”ì‹œì§€ ì„¸ì…˜ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # âœ… í•˜ë“œì½”ë”© ì‘ë‹µ
    mock_responses = {
        """ìµœê·¼ 6ê°œì›”ê°„ ì‹ í•œê¸ˆìœµê·¸ë£¹ì˜ AI ê¸°ë°˜ ì‹ ê·œ ì‚¬ì—… ê³µì‹œê°€ ìˆë‚˜ìš”?""" : """
            ë„¤, ìµœê·¼ 6ê°œì›”ê°„ ì‹ í•œê¸ˆìœµê·¸ë£¹ ì‚°í•˜ ì£¼ìš” ê³„ì—´ì‚¬ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ AI ê¸°ë°˜ ì‹ ê·œ ì‚¬ì—… ê³µì‹œê°€ ìˆì—ˆìŠµë‹ˆë‹¤:

            ì‹ í•œì€í–‰

            2024ë…„ 12ì›”: AI ê¸ˆìœµì§€ì‹ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶• ê³µì‹œ
            â†’ LG CNSì™€ í˜‘ì—…í•˜ì—¬ ìƒì„±í˜• AI ê¸°ë°˜ ì—…ë¬´ì§€ì‹ íƒìƒ‰ ì‹œìŠ¤í…œ ë„ì…
            â†’ ë‚´ë¶€ ë³´ì•ˆëª¨ë“ˆ â€˜SecuXper AIâ€™ í¬í•¨

            ì‹ í•œë¼ì´í”„

            2025ë…„ 1ì›”: AI ì½œë´‡ ê³ ê°ìƒë‹´ ìë™í™” ì‹œìŠ¤í…œ êµ¬ì¶•
            â†’ ë³´í—˜ ë¯¼ì› ìë™ì‘ëŒ€, FAQ ì¸ì‹ìœ¨ 87% ë‹¬ì„± ëª©í‘œ

            ì‹ í•œìºí”¼íƒˆ

            2025ë…„ 2ì›”: AI ì‹ ìš©í‰ê°€ ëª¨ë¸ ì •ì‹ ì „í™˜ ê³µì‹œ
            â†’ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ê¸°ì—… ì—¬ì‹ ì‹¬ì‚¬ ëª¨ë¸ ì ìš©

            âœ… í˜„ì¬ê¹Œì§€ ì´ 3ê±´ì˜ AI ê¸°ë°˜ ì‹ ê·œì‚¬ì—…ì´ ê³µì‹œë˜ì—ˆìœ¼ë©°,
            ì£¼ìš” í‚¤ì›Œë“œëŠ” ì§ˆì˜ì‘ë‹µí˜• AI, ìë™í™”, ì‹ ìš©í‰ê°€ ê³ ë„í™”ì…ë‹ˆë‹¤.
            """,
        "ê·¸ë£¹ì‚¬ì˜ ì‹œìŠ¤í…œì—ì„œ 2026ë…„ì— ì¥ë¹„ ë…¸í›„í™”ê°€ ì˜ˆìƒë˜ëŠ” ê²ƒì´ ìˆë‚˜ìš”?": """
        âœ… GPTí˜• ì±—ë´‡ ì‘ë‹µ ì˜ˆì‹œ:

        ì‹ í•œê¸ˆìœµê·¸ë£¹ì˜ 2025ë…„ 1ë¶„ê¸° ì‹œìŠ¤í…œ ìì‚°í˜„í™© ê¸°ì¤€ìœ¼ë¡œ,
        ë‹¤ìŒê³¼ ê°™ì€ ì¥ë¹„ê°€ 2026ë…„ ì¤‘ì  êµì²´ ëŒ€ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

        **ì‹ í•œì€í–‰**
        - ëŒ€ì™¸ê³„ ì„œë²„êµ° (AIX ê¸°ë°˜): 2017ë…„ ë„ì… â†’ 2026ë…„ 9ë…„ì°¨ ë„ë˜
        - WAF ì¥ë¹„ (ì›¹ë°©í™”ë²½): EOS ì˜ˆì •ì¼ 2026ë…„ 2ì›”

        **ì‹ í•œì¹´ë“œ**
        - ë¶„ì‚°íŒŒì¼ì €ì¥ì¥ì¹˜ (NAS): ìœ ì§€ë³´ìˆ˜ ë§Œë£Œ ì˜ˆì • 2026ë…„ 4ì›”
        - ê³ ê°ì ‘ì ìš© DID ì¸ì¦ì¥ë¹„: ë³´ì•ˆíŒ¨ì¹˜ ì¤‘ë‹¨ ì˜ˆì •

        **ê³µí†µ IDC ì¥ë¹„**
        - ì¼ë¶€ ì „ë ¥ê³µê¸‰ì¥ì¹˜(UPS) ë° ë„¤íŠ¸ì›Œí¬ ìŠ¤ìœ„ì¹˜ê°€
        ì œì¡°ì‚¬ ë³´ì¦ê¸°ê°„ ì¢…ë£Œ ë° MTBF ê¸°ì¤€ ë„ë˜ ì˜ˆì •

        âœ… ìœ„ ì¥ë¹„ë“¤ì€ ì˜ˆì‚° ê³„íš/Capex ë°˜ì˜ í•„ìš” í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.  
        â€» ì‹¤ì œ êµì²´ ì¼ì •ì€ ê°ì‚¬ IT ìš´ì˜ë³¸ë¶€ì˜ ìœ ì§€ê³„íšì— ë”°ë¦…ë‹ˆë‹¤.
        """,
        """ì‹ í•œì€í–‰ì˜ ì‚¬ì—… ê³µì‹œë¥¼ ë¶„ì„í•´ì„œ, ì •ë³´ë³´í˜¸ ì‚¬ì—… ì§„í–‰ ì‹œ í•„ìˆ˜ ë³´ì•ˆ S/Wë¥¼ ë‚˜ì—´í•´ì£¼ì„¸ìš”.""":"""
        ì‹ í•œì€í–‰ì˜ ì •ë³´ë³´í˜¸ ê´€ë ¨ ê³µì‹œ ë° RFP ê¸°ì¤€ì„ ë¶„ì„í•œ ê²°ê³¼,
        ì •ë³´ë³´í˜¸ ì‚¬ì—… ì¶”ì§„ ì‹œ ë°˜ë³µì ìœ¼ë¡œ ë“±ì¥í•˜ëŠ” í•„ìˆ˜ ë³´ì•ˆ ì†”ë£¨ì…˜ í•­ëª©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

        ì—”ë“œí¬ì¸íŠ¸ ë³´ì•ˆ

        EDR (Endpoint Detection & Response)

        ë°±ì‹  ë° ë¬´ê²°ì„± ì ê²€ ì†”ë£¨ì…˜

        ì ‘ê·¼í†µì œ

        DB ì ‘ê·¼ì œì–´ ì†”ë£¨ì…˜ (ex. PIM/PAM)

        ì„œë²„ì ‘ê·¼í†µì œ (2FA/OTP ê¸°ë°˜)

        í†µí•©ë³´ì•ˆ ê´€ë¦¬

        SIEM (í†µí•©ë¡œê·¸ë¶„ì„)

        NAC (ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ì œì–´)

        ì •ë³´ ìœ ì¶œ ë°©ì§€

        DLP (Data Loss Prevention)

        ë¬¸ì„œì¤‘ì•™í™” ì†”ë£¨ì…˜

        ì·¨ì•½ì  ê´€ë¦¬

        ìë™í™” ì·¨ì•½ì  ì ê²€ ë„êµ¬

        ì›¹ì‰˜ íƒì§€ ë° ì›¹ ë°©í™”ë²½(WAF)

        âœ… íŠ¹íˆ í´ë¼ìš°ë“œ ê¸°ë°˜ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ê²½ìš°,
        CASB, CSPM, SASE ë“±ì˜ ì‹ ê·œ ì˜ì—­ ë³´ì•ˆ ì†”ë£¨ì…˜ë„ í•¨ê»˜ ìš”êµ¬ë˜ê³  ìˆìŠµë‹ˆë‹¤.
        """
    }

    # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message['role']):
            st.write(message['content'])

            # feedback
            if message['role'] == 'ai' and not message.get("error", False):
                feedback_key = f"feedback_{idx}"
                user_feedback = st.session_state.get(feedback_key)
                col1, col2, _ = st.columns([2, 2, 6])
                with col1:
                    if user_feedback == "ì¢‹ì•„ìš”":
                        if st.button("ğŸ‘ì¢‹ì•„ìš”", key=f"like_{idx}"):
                            del st.session_state[feedback_key]
                            st.toast("ì¢‹ì•„ìš” ì„ íƒì´ ì·¨ì†Œë˜ì—ˆì–´ìš”.")
                            st.rerun()
                    else:
                        if st.button("ğŸ‘", key=f"like_{idx}"):
                            st.session_state[feedback_key] = "ì¢‹ì•„ìš”"
                            st.toast("ê°ì‚¬í•©ë‹ˆë‹¤. ì¢‹ì•„ìš”ë¥¼ ë‚¨ê²¼ì–´ìš”!")
                            st.rerun()
                with col2:
                    if user_feedback == "ë³„ë¡œì—ìš”":
                        if st.button("ğŸ‘ë³„ë¡œì—ìš”", key=f"dislike_{idx}"):
                            del st.session_state[feedback_key]
                            st.toast("ë³„ë¡œì—ìš” ì„ íƒì´ ì·¨ì†Œë˜ì—ˆì–´ìš”.")
                            st.rerun()
                    else:
                        if st.button("ğŸ‘", key=f"dislike_{idx}"):
                            st.session_state[feedback_key] = "ë³„ë¡œì—ìš”"
                            st.toast("ì˜ê²¬ ê°ì‚¬í•©ë‹ˆë‹¤. ê°œì„ ì— ì°¸ê³ í• ê²Œìš”!")
                            st.rerun()

    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    if "pending_user_input" in st.session_state:
        user_input = st.session_state.pending_user_input
        del st.session_state.pending_user_input

    if user_input:
        if len(user_input.strip()) < 2:
            st.warning("ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            st.stop()

        with st.chat_message("human"):
            st.write(user_input)
        st.session_state.messages.append({"role": "human", "content": user_input})

        # âœ… mock ì‘ë‹µ ì²˜ë¦¬
        if user_input in mock_responses:
            mock_reply = mock_responses[user_input]
            with st.chat_message("ai"):
                st.write(mock_reply)
            st.session_state.messages.append({"role": "ai", "content": mock_reply})
            st.rerun()

        # ğŸ¤– ì‹¤ì œ GPT í˜¸ì¶œ
        try:
            with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                completion = client.chat.completions.create(
                    model=gpt_model,
                    messages=[
                        {"role": "system", "content": gpt_content},
                        {"role": "user", "content": user_input}
                    ],
                )
                bot_response = completion.choices[0].message.content.strip()


                # langchain ì‚¬ìš©
                # print("user_input :" + user_input)
                # result = langchain(user_input)
            
                # if 0 < len(result["source_documents"]):
                #     source_doc = "\n\nì°¸ê³  ë¬¸ì„œ: " + str(result["source_documents"][0].metadata['source'])
                # else:
                #     source_doc = ""
        
                # bot_response = result["result"] + source_doc
                # # print(f"result : {result}")
                
                # elapsed = time.time() - start_time
                # print(f"â±ï¸ ì§ˆì˜ì‘ë‹µ ìˆ˜í–‰ : {elapsed:.4f}ì´ˆ")



            with st.chat_message("ai"):
                st.write(bot_response)
            st.session_state.messages.append({"role": "ai", "content": bot_response})
            st.rerun()

        except (APIConnectionError, RateLimitError):
            error_msg = "í˜„ì¬ ì„œë²„ ì—°ê²°ì´ ì›í™œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
            with st.chat_message("ai"):
                st.warning(error_msg)
            st.session_state.messages.append({"role": "ai", "content": error_msg, "error": True})
        except OpenAIError:
            error_msg = "AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            with st.chat_message("ai"):
                st.warning(error_msg)
            st.session_state.messages.append({"role": "ai", "content": error_msg, "error": True})
        except Exception:
            error_msg = "ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            with st.chat_message("ai"):
                st.warning(error_msg)
            st.session_state.messages.append({"role": "ai", "content": error_msg, "error": True})

    # âœ… ì…ë ¥ì°½ ì•„ë˜ ì”ìƒ ì œê±°ìš© CSS
    st.markdown("""
    <style>
    [data-testid="stChatInput"] {
        background: white !important;
        box-shadow: none !important;
        border: none !important;
        margin-bottom: 0rem !important;
    }

    section.main > div:has([data-testid="stChatInput"]) > div:nth-child(2) {
        display: none !important;
    }

    [data-testid="stChatInput"]::after {
        display: none !important;
    }

    .block-container {
        padding-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
